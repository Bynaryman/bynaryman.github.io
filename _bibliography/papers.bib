@phdthesis{ledoux:tel-04754167,
	TITLE = {{Floating-Point Arithmetic Paradigms for High-Performance Computing: Software Algorithms and Hardware Designs}},
	AUTHOR = {Ledoux, Louis},
	URL = {https://hal.science/tel-04754167},
	SCHOOL = {{Universitat Polit{\`e}cnica de Catalunya}},
	YEAR = {2024},
	MONTH = Oct,
	KEYWORDS = {Arithmetic ; Matrix Multiplication ; Workload Analysis ; HPC ; FPGA - field-Programmable gate array ; ASIC ; Arithm{\'e}tique IEEE 754 virgule flottante entiers},
	TYPE = {Theses}, PDF = {https://hal.science/tel-04754167v2/file/LEDOUX_Louis_Thesis.pdf},
	HAL_ID = {tel-04754167},
	HAL_VERSION = {v2},
  	selected = {false},
  	bibtex_show = {true},
  	preview = {collage_thesis_small.png},
  	html = {https://hal.science/tel-04754167},
	abstract = {This dissertation explores the challenges and advancements in arithmetic representations and computations within computer architectures, focusing on the limitations of the IEEE 754 standard. Modern computing demands, driven by advancements in AI, HPC, and scientific simulations, make efficient and precise numerical representations crucial. This work investigates these challenges and proposes innovative solutions, evaluating their impact on computational efficiency and accuracy. The core problem is the inefficiencies of the IEEE 754 standard for floating-point arithmetic, which do not meet the needs of modern workloads. These inefficiencies result in higher energy consumption, inadequate precision, and suboptimal performance, especially in energy-constrained environments and high-precision applications. To address these challenges, this thesis explores various facets of arithmetic computation, from algorithmic concepts to metal and silicon structures. It introduces mechanisms to improve the adaptability of numerical representations, allowing precision adjustments according to computational tasks, resulting in more efficient circuits. Focusing on improving arithmetic performance, the thesis addresses energy consumption and highlights the importance of efficient arithmetic logic units. It also shows how these solutions can be integrated into various software frameworks, revealing a correlation between numerical requirements and internal precision, highlighting an underexploited aspect of general-purpose floating-point formats. Firstly, it develops a framework for generating Posit operators in hardware, improving accuracy and performance in tasks like image classification. The Posit Operator Framework, described in SystemVerilog, enables the construction of Multi-Layer Perceptrons for inference engines, applicable in POWER9/CAPI2 environments with FPGA acceleration. Secondly, it presents a generator for Systolic Arrays optimized for Matrix-Matrix Multiplication (MMM), showing the impact of custom hardware configurations on accuracy and energy efficiency. The MMM units are fully parametrizable and adapted to the numerical specifications of the workload, facilitated by a core generator with automated pipelining. These units allow evaluations with CAPI2 on FPGA and POWER9 systems, achieving up to two Tera floating-point operations per second. They have also demonstrated success in ASIC generation. Additionally, it establishes an open-source framework to integrate MMM units into high-level software, offering energy savings and enhanced precision for applications like AI and scientific computations. The methodology involves mapping General Matrix-Matrix Multiplication calls in BLAS libraries to our accelerators via the OpenCAPI coherent link, saturating the 22 GBps bandwidth by tuning computer formats to accommodate more Processing Elements while preserving accuracy. Finally, the resurgence of vector processing leads to a reevaluation of division algorithms, revealing opportunities to use smaller and slower computing units, allowing more units within varied energy and power budgets. This approach shows a broad Design Space Exploration. We developed an open-source EDA ASIC flow, facilitating parallel generation of multiple chip designs, enabling systematic exploration of power, performance, and area across various process design kits to identify optimal configurations. These contributions form an interdisciplinary thesis that advances solutions to computing challenges from an arithmetic perspective, overcoming the "arithmetic wall."},
}

@poster{ledoux_suf_2024,
  TITLE = {{The Grafted Superset Approach: Bridging Python to Silicon with Asynchronous Compilation and Beyond}},
  AUTHOR = {Ledoux, Louis and Casas, Marc},
  URL = {https://hal.science/hal-04587458},
  NOTE = {Poster},
  HOWPUBLISHED = {{DATE}},
  YEAR = {2024},
  MONTH = Mar,
  KEYWORDS = {EDA ; ASIC ; flow ; Open Source Silicon ; Arithmetic ; Floating-Point ; Automated Pipeline ; FloPoCo},
  PDF = {https://hal.science/hal-04587458v1/file/poster.pdf},
  HAL_ID = {hal-04587458},
  HAL_VERSION = {v1},
  selected = {false},
  bibtex_show = {true},
  preview = {suf_preview_small.png},
  html = {https://hal.science/hal-04587458},
  abbr = {DATE}
}

@misc{ledoux_llmmmm_2024,
  TITLE = {{LLMMMM: Large Language Models Matrix-Matrix Multiplications Characterization on Open Silicon}},
  AUTHOR = {Ledoux, Louis and Casas, Marc},
  URL = {https://hal.science/hal-04592229},
  NOTE = {Poster},
  HOWPUBLISHED = {{11th BSC Symposium}},
  ORGANIZATION = {{Barcelona Supercomputing Center}},
  VOLUME = {11},
  YEAR = {2024},
  MONTH = May,
  KEYWORDS = {Multi-Perspective Layout visualizations and Power Performance Area (PPA) Analysis introduction of PPAA (Power Performance Area Accuracy) metric PDK vs. Computer format ASAP7: 4096 PEs 8.2 TFLOP/s <1 mm 2 Congestion heatmap 64 PEs e4m3-$\beta$ 8 ; Multi-Perspective Layout visualizations and Power ; Performance ; Area (PPA) Analysis introduction of PPAA (Power ; Area ; Accuracy) metric PDK vs. Computer format ASAP7: 4096 PEs ; 8.2 TFLOP/s ; <1 mm 2 Congestion heatmap ; 64 PEs ; e4m3-$\beta$ 8},
  PDF = {https://hal.science/hal-04592229v1/file/poster_a0.pdf},
  HAL_ID = {hal-04592229},
  HAL_VERSION = {v1},
  selected = {true},
  bibtex_show = {true},
  preview = {llmmmm_preview_small.png},
  html = {https://hal.science/hal-04592229v1}
}

@misc{ledoux_osfntc_poster_2023,
  TITLE = {{An Open-Source Framework for Efficient Numerically-Tailored Computations}},
  AUTHOR = {Ledoux, Louis and Casas, Marc},
  URL = {https://hal.science/hal-04094835},
  NOTE = {Poster},
  HOWPUBLISHED = {{BSCSymposium23}},
  ORGANIZATION = {{Barcelona Supercomputing Center}},
  YEAR = {2023},
  MONTH = May,
  KEYWORDS = {GEMMs ; matrix-matrix-multiply ; full stack framework ; automated pipeline ; flopoco ; OpenCAPI ; OpenBLAS ; High Performance Computing ; approximate/trans/extended precision},
  PDF = {https://hal.science/hal-04094835v1/file/BSC_Symposium_10_Louis_Ledoux_final.pdf},
  HAL_ID = {hal-04094835},
  HAL_VERSION = {v1},
  selected = {false},
  bibtex_show = {true},
  preview = {osfntc_preview_small.png},
  html = {https://hal.science/hal-04094835}
}

@inproceedings{ledoux_generator_2022,
	title = {A {Generator} of {Numerically}-{Tailored} and {High}-{Throughput} {Accelerators} for {Batched} {GEMMs}},
	doi = {10.1109/FCCM53951.2022.9786164},
	abstract = {We propose a hardware generator of GEMM accelerators. Our generator produces vendor-agnostic HDL describing highly customizable systolic arrays guided by accuracy and energy efficiency goals. The generated arrays have three main novel aspects. First, the accelerators handle a large variety of computer number formats using intermediate representations based on our Sign Scale Significand (S3) format. Second, the processing elements perform all intermediate dot-product arithmetic operations required by the GEMM kernel without any intermediate rounding, which makes it possible to deliver better energy efficiency than state-of-the-art approaches while offering more accuracy and reproducible results. Third, our accelerators feature the Half-Speed Sink Down (HSSD) mechanism, which maximizes the overlap of host-accelerator data transfers with GEMM computations.We evaluate our automatically generated designs in a cutting-edge setup composed of a POWER9 host, CAPI (Coherent Accelerator Processor Interface) link, and a Virtex Ultrascale Plus FPGA. Arrays can operate at the speed of the link and saturate it to reach a 13GB/s throughput. Our fine-grain customization approach allows to cover a wide range of accuracy versus efficiency scenarios and can reach 0.65GOps/s/W while producing 1024 accurate bits or 148.7GOps/s/W with 6 accurate bits. Our configurations achieve up to 1613GOps/s system performance and power efficiencies of up to 240GOps/s/W for the FPGA. This automatic generator is the first being able to produce such a variety of designs. We improve the single-precision energy efficiency of state-of-the-art FPGA GEMM accelerators by 1.86Ã—.},
	booktitle = {2022 {IEEE} 30th {Annual} {International} {Symposium} on {Field}-{Programmable} {Custom} {Computing} {Machines} ({FCCM})},
	author = {Ledoux, Louis and Casas, Marc},
	month = may,
	year = {2022},
	pages = {1--10},
	selected = {true},
	bibtex_show = {true},
	google_scholar_id = {u5HHmVD_uO8C},
	preview = {placement.gif},
	html = {https://ieeexplore.ieee.org/document/9786164},
	abbr = {FCCM}
}


@inproceedings{ledoux_framework_2023,
	title = {An {Open}-{Source} {Framework} for {Efficient} {Numerically}-{Tailored} {Computations}},
	url = {https://ieeexplore.ieee.org/document/10296314},
	doi = {10.1109/FPL60245.2023.00011},
	abstract = {We present a versatile open-source framework designed to facilitate efficient, numerically-tailored Matrix-Matrix Multiplications (MMMs). The framework offers two primary contributions: first, a fine-tuned, automated pipeline for arithmetic datapath generation, enabling highly customizable systolic MMM kernels; second, seamless integration of the generated kernels into user code, irrespective of the programming language employed, without necessitating modifications. We employ this framework within a cutting-edge platform, comprising a Power9 host, an OpenCAPI link, and a Xilinx Virtex UltraScale+ FPGA. The framework demonstrates a systematic enhancement in accuracy per energy cost across diverse High Performance Computing (HPC) workloads displaying a variety of numerical requirements, such as Artificial Intelligence (AI) inference and Sea Surface Height (SSH) computation. For AI inference, we consider a set of state-of-the-art neural network models, namely ResNetl8, ResNet34, ResNet50, DenseNet121, DenseNet161, DenseNet169, and VGG11, in conjunction with two datasets, two computer formats, and 27 distinct intermediate arithmetic datapaths. Our approach consistently reduces energy consumption across all cases, with a notable example being the reduction by factors of 3.3x for IEEE754-32 and 1.4x for Bfloat16 during ImageNet inference with ResNet50. This is accomplished while maintaining accuracies of 82.3\% and 86\%, comparable to those achieved with conventional Floating-Point Units (FPUs). In the context of SSH computation, our method achieves fully-reproducible results using double-precision words, surpassing the accuracy of conventional double- and quad-precision arithmetic in FPUs. Our approach enhances SSH computation accuracy by a minimum of 5Ã— and 27Ã— compared to IEEE754-64 and IEEE754-128, respectively, resulting in 5.6Ã— and 15.1 Ã— improvements in accuracy per power cost.},
	booktitle = {2023 33rd {International} {Conference} on {Field}-{Programmable} {Logic} and {Applications} ({FPL})},
	author = {Ledoux, Louis and Casas, Marc},
	month = sep,
	year = {2023},
	note = {ISSN: 1946-1488},
	pages = {19--26},
	selected = {true},
	bibtex_show = {true},
	google_scholar_id = {d1gkVwhDpl0C},
	preview = {tailored.png},
	html = {https://ieeexplore.ieee.org/document/10296314},
	abbr = {FPL}

}

@techreport{ledoux_accelerating_2019,
	address = {Lyon, France},
	title = {Accelerating {DL} inference with ({Open}){CAPI} and posit numbers},
	url = {https://hal.science/hal-04094850},
	abstract = {In order to tackle the communication-bound problems in heterogeneous systems, Louis discussed how intrinsic arithmetics can have significant impacts on energy and throughputs.

Thanks to the denser representation offered by the posit arithmetic BSC can:
- significantly divide bandwidth needed (PCIE: HOST - FPGA)
- maintain all weights on chip
- save power consumption},
	booktitle = {{OpenPOWER} summit 2019},
	publisher = {linux foundation},
	author = {Ledoux, Louis and Casas, Marc},
	month = oct,
	year = {2019},
	keywords = {acceleration, CAPI, CAPI2, FPGA, PCIE, posit, POWER9},
	abbr = {OpenPOWER},
	bibtex_show = {true},
	preview = {posit_mlp_preview_small.png},
	html = {https://hal.science/hal-04094850},
}
